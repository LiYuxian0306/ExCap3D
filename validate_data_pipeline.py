"""
æ•°æ®æµç¨‹éªŒè¯è„šæœ¬
éªŒè¯ prepare_training_data.py â†’ sample_pth.py â†’ scannetpp_pth_preprocessing.py çš„æ•°æ®æ ¼å¼

ä½¿ç”¨æ–¹æ³•:
python validate_data_pipeline.py --scene_id <scene_name>

ä¾‹å¦‚:
python validate_data_pipeline.py --scene_id 0a5c013435
"""

import argparse
import json
import numpy as np
import torch
from pathlib import Path
import sys

if hasattr(np, 'core'):
    # 1. æ˜ å°„ numpy._core -> np.core
    if 'numpy._core' not in sys.modules:
        sys.modules['numpy._core'] = np.core
    
    # 2. æ˜ å°„ numpy._core.multiarray -> np.core.multiarray(å› ä¸ºç‰ˆæœ¬é—®é¢˜æœ‰æŠ¥é”™aaa)
    if hasattr(np.core, 'multiarray') and 'numpy._core.multiarray' not in sys.modules:
        sys.modules['numpy._core.multiarray'] = np.core.multiarray


def print_separator(title):
    """æ‰“å°åˆ†éš”çº¿"""
    print("\n" + "="*80)
    print(f"  {title}")
    print("="*80 + "\n")


def validate_prepare_training_data_output(scene_id, pth_dir):
    """éªŒè¯ prepare_training_data.py çš„è¾“å‡º (.pth æ–‡ä»¶)"""
    print_separator(f"ç¬¬ 1 æ­¥: prepare_training_data.py è¾“å‡ºéªŒè¯ - {scene_id}")
    
    pth_file = Path(pth_dir) / f"{scene_id}.pth"
    
    if not pth_file.exists():
        print(f"âŒ é”™è¯¯: PTH æ–‡ä»¶ä¸å­˜åœ¨: {pth_file}")
        return None
    
    print(f"âœ… æ–‡ä»¶å­˜åœ¨: {pth_file}")
    
    # åŠ è½½æ•°æ®
    pth_data = torch.load(pth_file)
    
    print(f"\nğŸ“Š æ•°æ®é”®åˆ—è¡¨:")
    for key in sorted(pth_data.keys()):
        if isinstance(pth_data[key], (np.ndarray, torch.Tensor)):
            shape = pth_data[key].shape
            dtype = pth_data[key].dtype
            print(f"  - {key:30s}: shape={shape}, dtype={dtype}")
        else:
            print(f"  - {key:30s}: {type(pth_data[key]).__name__} = {pth_data[key]}")
    
    # è¯¦ç»†æ£€æŸ¥å…³é”®å­—æ®µ
    print(f"\nğŸ” è¯¦ç»†æ£€æŸ¥:")
    
    # æ£€æŸ¥åæ ‡
    if 'vtx_coords' in pth_data:
        coords = pth_data['vtx_coords']
        print(f"  vtx_coords: {len(coords)} ä¸ªç‚¹")
        print(f"    èŒƒå›´: X[{coords[:, 0].min():.2f}, {coords[:, 0].max():.2f}], "
              f"Y[{coords[:, 1].min():.2f}, {coords[:, 1].max():.2f}], "
              f"Z[{coords[:, 2].min():.2f}, {coords[:, 2].max():.2f}]")
    
    # æ£€æŸ¥é¢œè‰²
    if 'vtx_colors' in pth_data:
        colors = pth_data['vtx_colors']
        print(f"  vtx_colors: èŒƒå›´ [{colors.min():.3f}, {colors.max():.3f}] (åº”è¯¥åœ¨ [0, 1])")
    
    # æ£€æŸ¥è¯­ä¹‰æ ‡ç­¾
    if 'vtx_labels' in pth_data:
        labels = pth_data['vtx_labels']
        unique_labels = np.unique(labels)
        print(f"  vtx_labels: {len(unique_labels)} ä¸ªå”¯ä¸€æ ‡ç­¾")
        print(f"    èŒƒå›´: [{labels.min()}, {labels.max()}]")
        print(f"    å‰ 10 ä¸ªå”¯ä¸€æ ‡ç­¾: {unique_labels[:10]}")
        print(f"    -100 (ignore) ç‚¹æ•°: {(labels == -100).sum()}")
    
    # æ£€æŸ¥å®ä¾‹æ ‡ç­¾
    if 'vtx_instance_anno_id' in pth_data:
        inst_labels = pth_data['vtx_instance_anno_id']
        unique_inst = np.unique(inst_labels[inst_labels != -100])
        print(f"  vtx_instance_anno_id: {len(unique_inst)} ä¸ªå®ä¾‹")
        print(f"    èŒƒå›´: [{inst_labels.min()}, {inst_labels.max()}]")
        print(f"    å®ä¾‹ ID åˆ—è¡¨: {unique_inst[:20]}")
        print(f"    -100 (ignore) ç‚¹æ•°: {(inst_labels == -100).sum()}")
    
    # æ£€æŸ¥ segment IDs
    if 'vtx_segment_ids' in pth_data:
        seg_ids = pth_data['vtx_segment_ids']
        unique_segs = np.unique(seg_ids)
        print(f"  vtx_segment_ids: {len(unique_segs)} ä¸ªå”¯ä¸€ segment")
        print(f"    èŒƒå›´: [{seg_ids.min()}, {seg_ids.max()}]")
    
    return pth_data


def validate_sample_pth_output(scene_id, sampled_dir):
    """éªŒè¯ sample_pth.py çš„è¾“å‡º (é‡‡æ ·åçš„ .pth æ–‡ä»¶)"""
    print_separator(f"ç¬¬ 2 æ­¥: sample_pth.py è¾“å‡ºéªŒè¯ - {scene_id}")
    
    pth_file = Path(sampled_dir) / f"{scene_id}.pth"
    
    if not pth_file.exists():
        print(f"âŒ é”™è¯¯: é‡‡æ ·åçš„ PTH æ–‡ä»¶ä¸å­˜åœ¨: {pth_file}")
        return None
    
    print(f"âœ… æ–‡ä»¶å­˜åœ¨: {pth_file}")
    
    # åŠ è½½æ•°æ®
    pth_data = torch.load(pth_file)
    
    print(f"\nğŸ“Š æ•°æ®é”®åˆ—è¡¨:")
    for key in sorted(pth_data.keys()):
        if isinstance(pth_data[key], (np.ndarray, torch.Tensor)):
            shape = pth_data[key].shape
            dtype = pth_data[key].dtype
            print(f"  - {key:30s}: shape={shape}, dtype={dtype}")
        else:
            print(f"  - {key:30s}: {type(pth_data[key]).__name__} = {pth_data[key]}")
    
    # è¯¦ç»†æ£€æŸ¥
    print(f"\nğŸ” è¯¦ç»†æ£€æŸ¥:")
    
    if 'vtx_coords' in pth_data:
        coords = pth_data['vtx_coords']
        print(f"  vtx_coords: {len(coords)} ä¸ªé‡‡æ ·ç‚¹")
        print(f"    èŒƒå›´: X[{coords[:, 0].min():.2f}, {coords[:, 0].max():.2f}], "
              f"Y[{coords[:, 1].min():.2f}, {coords[:, 1].max():.2f}], "
              f"Z[{coords[:, 2].min():.2f}, {coords[:, 2].max():.2f}]")
    
    if 'vtx_colors' in pth_data:
        colors = pth_data['vtx_colors']
        print(f"  vtx_colors: èŒƒå›´ [{colors.min():.3f}, {colors.max():.3f}]")
    
    # æ£€æŸ¥æ³•å‘é‡ï¼ˆæ–°å¢ï¼‰
    if 'vtx_normals' in pth_data:
        normals = pth_data['vtx_normals']
        print(f"  âœ… vtx_normals: shape={normals.shape}, æ³•å‘é‡å­˜åœ¨")
        norms = np.linalg.norm(normals, axis=1)
        print(f"    æ³•å‘é‡é•¿åº¦èŒƒå›´: [{norms.min():.3f}, {norms.max():.3f}] (åº”è¯¥æ¥è¿‘ 1.0)")
    else:
        print(f"  âš ï¸  vtx_normals: ä¸å­˜åœ¨ï¼ˆå¯èƒ½å½±å“è®­ç»ƒæ•ˆæœï¼‰")
    
    if 'vtx_labels' in pth_data:
        labels = pth_data['vtx_labels']
        unique_labels = np.unique(labels)
        print(f"  vtx_labels: {len(unique_labels)} ä¸ªå”¯ä¸€æ ‡ç­¾, èŒƒå›´ [{labels.min()}, {labels.max()}]")
    
    if 'vtx_instance_anno_id' in pth_data:
        inst_labels = pth_data['vtx_instance_anno_id']
        unique_inst = np.unique(inst_labels[inst_labels != -100])
        print(f"  vtx_instance_anno_id: {len(unique_inst)} ä¸ªå®ä¾‹")
    
    if 'vtx_segment_ids' in pth_data:
        seg_ids = pth_data['vtx_segment_ids']
        unique_segs = np.unique(seg_ids)
        print(f"  vtx_segment_ids: {len(unique_segs)} ä¸ªå”¯ä¸€ segment")
        print(f"    èŒƒå›´: [{seg_ids.min()}, {seg_ids.max()}]")
    
    return pth_data


def validate_preprocessing_output(scene_id, processed_dir):
    """éªŒè¯ scannetpp_pth_preprocessing.py çš„è¾“å‡º (.npy å’Œ .txt æ–‡ä»¶)"""
    print_separator(f"ç¬¬ 3 æ­¥: scannetpp_pth_preprocessing.py è¾“å‡ºéªŒè¯ - {scene_id}")
    
    # æ£€æŸ¥ .npy æ–‡ä»¶ (å¯èƒ½åœ¨ train æˆ– validation å­ç›®å½•)
    npy_file = None
    for subdir in ['train', 'validation', 'test']:
        candidate = Path(processed_dir) / subdir / f"{scene_id}.npy"
        if candidate.exists():
            npy_file = candidate
            print(f"âœ… æ‰¾åˆ° NPY æ–‡ä»¶: {npy_file}")
            break
    
    if npy_file is None:
        print(f"âŒ é”™è¯¯: NPY æ–‡ä»¶ä¸å­˜åœ¨äº train/validation/test å­ç›®å½•")
        return None
    
    # åŠ è½½ npy æ•°æ®
    points = np.load(npy_file)
    
    print(f"\nğŸ“Š NPY æ–‡ä»¶æ•°æ®:")
    print(f"  shape: {points.shape} (åº”è¯¥æ˜¯ N Ã— 10)")
    print(f"  dtype: {points.dtype}")
    
    print(f"\nğŸ” å„åˆ—è¯¦ç»†ä¿¡æ¯:")
    print(f"  åˆ— 0-2 (coords):")
    print(f"    X: [{points[:, 0].min():.2f}, {points[:, 0].max():.2f}]")
    print(f"    Y: [{points[:, 1].min():.2f}, {points[:, 1].max():.2f}]")
    print(f"    Z: [{points[:, 2].min():.2f}, {points[:, 2].max():.2f}]")
    
    print(f"  åˆ— 3-5 (colors):")
    print(f"    R: [{points[:, 3].min():.2f}, {points[:, 3].max():.2f}] (åº”è¯¥åœ¨ [0, 255])")
    print(f"    G: [{points[:, 4].min():.2f}, {points[:, 4].max():.2f}]")
    print(f"    B: [{points[:, 5].min():.2f}, {points[:, 5].max():.2f}]")
    
    print(f"  åˆ— 6-8 (normals):")
    print(f"    NX: [{points[:, 6].min():.2f}, {points[:, 6].max():.2f}]")
    print(f"    NY: [{points[:, 7].min():.2f}, {points[:, 7].max():.2f}]")
    print(f"    NZ: [{points[:, 8].min():.2f}, {points[:, 8].max():.2f}]")
    
    print(f"  åˆ— 9 (unique_segment_ids):")
    unique_seg_ids = np.unique(points[:, 9])
    print(f"    å”¯ä¸€å€¼æ•°é‡: {len(unique_seg_ids)}")
    print(f"    èŒƒå›´: [{points[:, 9].min():.0f}, {points[:, 9].max():.0f}]")
    print(f"    æ˜¯å¦è¿ç»­ä» 0 å¼€å§‹: {np.array_equal(unique_seg_ids, np.arange(len(unique_seg_ids)))}")
    
    print(f"  åˆ— 10 (semantic_labels):")
    semantic_labels = points[:, 10]
    unique_sem = np.unique(semantic_labels)
    print(f"    å”¯ä¸€å€¼æ•°é‡: {len(unique_sem)}")
    print(f"    èŒƒå›´: [{semantic_labels.min():.0f}, {semantic_labels.max():.0f}]")
    print(f"    å”¯ä¸€æ ‡ç­¾: {unique_sem[:15]}")
    
    print(f"  åˆ— 11 (instance_labels):")
    instance_labels = points[:, 11]
    unique_inst = np.unique(instance_labels[instance_labels != -100])
    print(f"    å”¯ä¸€å®ä¾‹æ•°é‡: {len(unique_inst)} (ä¸å« -100)")
    print(f"    èŒƒå›´: [{instance_labels.min():.0f}, {instance_labels.max():.0f}]")
    print(f"    å®ä¾‹ ID: {unique_inst[:20]}")
    
    # æ£€æŸ¥ ground truth æ–‡ä»¶
    gt_file = None
    for subdir in ['train', 'validation', 'test']:
        candidate = Path(processed_dir) / "instance_gt" / subdir / f"{scene_id}.txt"
        if candidate.exists():
            gt_file = candidate
            print(f"\nâœ… æ‰¾åˆ° GT æ–‡ä»¶: {gt_file}")
            break
    
    if gt_file:
        gt_data = np.loadtxt(gt_file, dtype=np.int32)
        print(f"\nğŸ“Š Ground Truth æ–‡ä»¶:")
        print(f"  shape: {gt_data.shape}")
        print(f"  èŒƒå›´: [{gt_data.min()}, {gt_data.max()}]")
        print(f"  å”¯ä¸€å€¼æ•°é‡: {len(np.unique(gt_data))}")
        
        # éªŒè¯ GT è®¡ç®—å…¬å¼: semantic_id Ã— 1000 + instance_id + 1
        computed_gt = (semantic_labels * 1000 + instance_labels + 1).astype(np.int32)
        if np.array_equal(gt_data, computed_gt):
            print(f"  âœ… GT éªŒè¯é€šè¿‡: semantic_id Ã— 1000 + instance_id + 1")
        else:
            diff = (gt_data != computed_gt).sum()
            print(f"  âš ï¸  GT éªŒè¯å¤±è´¥: {diff} ä¸ªä¸åŒ¹é…ç‚¹")
    else:
        print(f"âŒ é”™è¯¯: GT æ–‡ä»¶ä¸å­˜åœ¨")
    
    return points


def validate_segments_consistency(scene_id, data_root):
    """éªŒè¯ segments.json å’Œ segments_anno.json çš„ä¸€è‡´æ€§"""
    print_separator(f"é¢å¤–æ£€æŸ¥: Segment ID ä¸€è‡´æ€§ - {scene_id}")
    
    segments_file = Path(data_root) / scene_id / "scans" / "segments.json"
    anno_file = Path(data_root) / scene_id / "scans" / "segments_anno.json"
    
    if not segments_file.exists():
        print(f"âŒ segments.json ä¸å­˜åœ¨: {segments_file}")
        return
    
    if not anno_file.exists():
        print(f"âŒ segments_anno.json ä¸å­˜åœ¨: {anno_file}")
        return
    
    print(f"âœ… æ–‡ä»¶å­˜åœ¨")
    
    # è¯»å–æ•°æ®
    with open(segments_file) as f:
        segments = json.load(f)
    
    with open(anno_file) as f:
        anno = json.load(f)
    
    seg_indices = np.array(segments['segIndices'], dtype=np.int32)
    
    # æ”¶é›†æ‰€æœ‰æ ‡æ³¨çš„ segment IDs
    all_anno_segments = set()
    for group in anno['segGroups']:
        all_anno_segments.update(group['segments'])
    
    # ç»Ÿè®¡
    unique_seg_indices = set(seg_indices)
    intersection = unique_seg_indices & all_anno_segments
    
    print(f"\nğŸ“Š Segment ID ç»Ÿè®¡:")
    print(f"  segments.json:")
    print(f"    æ€»ç‚¹æ•°: {len(seg_indices)}")
    print(f"    å”¯ä¸€ segment ID æ•°é‡: {len(unique_seg_indices)}")
    print(f"    ID èŒƒå›´: [{seg_indices.min()}, {seg_indices.max()}]")
    
    print(f"\n  segments_anno.json:")
    print(f"    æ ‡æ³¨å¯¹è±¡æ•°é‡: {len(anno['segGroups'])}")
    print(f"    æ ‡æ³¨çš„ segment ID æ•°é‡: {len(all_anno_segments)}")
    print(f"    ID èŒƒå›´: [{min(all_anno_segments)}, {max(all_anno_segments)}]")
    
    print(f"\n  ä¸€è‡´æ€§æ£€æŸ¥:")
    print(f"    äº¤é›†æ•°é‡: {len(intersection)}")
    print(f"    äº¤é›†æ¯”ä¾‹ (ç›¸å¯¹äº segments.json): {len(intersection) / len(unique_seg_indices) * 100:.2f}%")
    print(f"    äº¤é›†æ¯”ä¾‹ (ç›¸å¯¹äº segments_anno.json): {len(intersection) / len(all_anno_segments) * 100:.2f}%")
    
    if len(intersection) / len(unique_seg_indices) < 0.5:
        print(f"  âš ï¸  è­¦å‘Š: äº¤é›†æ¯”ä¾‹è¿‡ä½ï¼Œå¯èƒ½å­˜åœ¨ ID ä¸ä¸€è‡´é—®é¢˜ï¼")
    else:
        print(f"  âœ… Segment ID æ˜ å°„æ­£å¸¸")
    
    # æ£€æŸ¥æ ‡æ³¨å¯¹è±¡çš„æ ‡ç­¾åˆ†å¸ƒ
    print(f"\nğŸ“Š æ ‡æ³¨å¯¹è±¡æ ‡ç­¾ç»Ÿè®¡:")
    label_counts = {}
    for group in anno['segGroups']:
        label = group.get('label', 'unknown')
        label_counts[label] = label_counts.get(label, 0) + 1
    
    sorted_labels = sorted(label_counts.items(), key=lambda x: x[1], reverse=True)
    print(f"  æ€»è®¡ {len(label_counts)} ç§æ ‡ç­¾:")
    for label, count in sorted_labels[:20]:
        print(f"    {label:30s}: {count:3d} ä¸ªå¯¹è±¡")


def main():
    parser = argparse.ArgumentParser(description='éªŒè¯ ExCap3D æ•°æ®å¤„ç†æµç¨‹')
    parser.add_argument('--scene_id', type=str, required=True, 
                        help='è¦éªŒè¯çš„åœºæ™¯ IDï¼Œä¾‹å¦‚: 0a5c013435')
    parser.add_argument('--data_root', type=str, 
                        default='/home/kylin/datasets/scannetpp_v2/scannetpp/data/',
                        help='scannetpp æ•°æ®æ ¹ç›®å½•')
    parser.add_argument('--input_pth_dir', type=str,
                        default='/home/kylin/lyx/project_study/ExCap3D/data/semantic_processed/semantic_processed_unchunked',
                        help='prepare_training_data.py è¾“å‡ºç›®å½•')
    parser.add_argument('--sampled_dir', type=str,
                        default='/home/kylin/lyx/project_study/ExCap3D/data/sampled/',
                        help='sample_pth.py è¾“å‡ºç›®å½•')
    parser.add_argument('--processed_dir', type=str,
                        default='/home/kylin/lyx/project_study/ExCap3D/data/processed/',
                        help='scannetpp_pth_preprocessing.py è¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                       ExCap3D æ•°æ®æµç¨‹éªŒè¯å·¥å…·                              â•‘
â•‘                                                                              â•‘
â•‘  åœºæ™¯ ID: {args.scene_id:60s}    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")
    
    # éªŒè¯å„ä¸ªé˜¶æ®µ
    try:
        # ç¬¬ 1 æ­¥ï¼šprepare_training_data.py è¾“å‡º
        pth_data_1 = validate_prepare_training_data_output(
            args.scene_id, 
            args.input_pth_dir
        )
        
        # ç¬¬ 2 æ­¥ï¼šsample_pth.py è¾“å‡º
        pth_data_2 = validate_sample_pth_output(
            args.scene_id,
            args.sampled_dir
        )
        
        # ç¬¬ 3 æ­¥ï¼šscannetpp_pth_preprocessing.py è¾“å‡º
        npy_data = validate_preprocessing_output(
            args.scene_id,
            args.processed_dir
        )
        
        # é¢å¤–æ£€æŸ¥ï¼šsegment ID ä¸€è‡´æ€§
        validate_segments_consistency(
            args.scene_id,
            args.data_root
        )
        
        # æœ€ç»ˆæ€»ç»“
        print_separator("éªŒè¯æ€»ç»“")
        
        success_count = sum([
            pth_data_1 is not None,
            pth_data_2 is not None,
            npy_data is not None
        ])
        
        print(f"âœ… æˆåŠŸéªŒè¯: {success_count}/3 ä¸ªé˜¶æ®µ")
        
        if success_count == 3:
            print(f"\nğŸ‰ æ‰€æœ‰æ•°æ®æ ¼å¼éªŒè¯é€šè¿‡ï¼å¯ä»¥è¿›è¡Œè®­ç»ƒã€‚")
        else:
            print(f"\nâš ï¸  éƒ¨åˆ†éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯ã€‚")
        
    except Exception as e:
        print(f"\nâŒ éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯:")
        print(f"  {type(e).__name__}: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
